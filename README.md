## 参考资料

- 数学
  
  - 微积分
  
  - 线性代数与矩阵运算
  
  - 概率论与随机过程
  
  - 《统计学习方法》李航, 清华大学出版社

- 机器学习
  
  - [GitHub - microsoft - ML-For-Beginners](https://github.com/microsoft/ML-For-Beginners/tree/main)

- 深度学习基础
  
  - 《深入浅出神经网络与深度学习》ichael Nielsen, 人民邮电出版社 // 推荐指数3.5。浅显易懂，包含了初学者想知道但不一定能系统找到的细节
  
  - [《深度学习》](http://www.deeplearningbook.org/)Ian Goodfellow, Yoshua Bengio, Aaron Courville, 人民邮电出版社 // 很经典的书，但是还没看完... 
  
  - [《动手学深度学习》](https://zh.d2l.ai/) 李宏毅 // 很经典的书，但是还没看...

- 强化学习基础
  
  - 《大模型算法：强化学习、微调与对齐》余昌叶, 电子工业出版社 // 推荐指数4.5。这本书图表丰富，偏向于原理解释，最重要的是内容结构清晰，有助于构建知识体系
  
  - [GitHub - changyeyu/LLM-RL-Visualized](https://github.com/changyeyu/LLM-RL-Visualized) // 《大模型算法》中的图表
  
  - 《强化学习 第二版》理查德·萨顿, 电子工业出版社 // 推荐指数3.5。强化学习的圣经，充满了理论叙述和数学推导。书是好书，术语和符号体系和常见论文有一点点出入，其次内容过于偏底层原理，看着累，只看了一半... 这书适合慢慢看

- 大模型
  
  - [GitHub -《大模型基础》](https://github.com/ZJU-LLMs/Foundations-of-LLMs) 毛玉仁, 高云君 // 推荐指数4，很适合入门
  
  - 《GPT图解：大模型是怎样构建的》黄佳, 人民邮电出版社出版 // 推荐指数3。缺点是字太小，而且没想象中的那么好读。按个人喜好，那就是建议选读部分感兴趣的章节
  
  - 《大规模语言模型 - 从理论到实践（第2版）》张奇, 桂韬等, 电子工业出版社 // 推荐指数2。内容写的一板一眼，排版还有点密集，让人抓不到重点。优点是引了不少论文，没事翻几页。说不定能意外看到几篇不错的论文。不适合初学者。
  
  - 《从零构建大模型》Sebastian Raschka, 人民邮电出版社 // 推荐指数3
  
  - 《基于大模型的RAG应用开发与优化——构建企业级LLM应用》严灿平, 电子工业出版社 // 推荐指数3.5。这书分预备篇、基础篇、高级篇三部分。前两篇讲大模型和RAG的基础知识，稍微有点基础的人看着会觉得无聊，加上全书以LlamaIndex框架为基础，并贴了很多示例代码，就像LlamaIndex入门手册。但是，如果对RAG应用不太熟，还是很推荐看看，特别是第7章。相对而言，高级篇更有意思，特别是11-13章，能帮你系统的梳理开发企业RAG应用的知识点。全书示例代码很多，如果只是按需查看，读起来就很快。

- 效率
  
  - 《高效深度学习——模型压缩与设计》汪玉, 电子工业出版社 // 推荐指数3。涉及剪枝、量化、二值化、模型架构搜索、蒸馏等。大量内容是基于传统小模型写的，和LLM的关联性没有预想的强。各主题写的不够深入，有点像导读。书的内容偏理论或者研究介绍，实践部分少。好在语言流畅度还凑合，挑感兴趣的章节看，很快就能看完。

<br>

关于推荐指数：

这是个人阅读后的主观评分，仅供参考。如有问题，以你为准。

- 推荐指数1，完全不推荐。存在严重的错误，或者知识量极少且阅读难度很高

- 推荐指数2，不推荐。看了等于白看的浪费时间，或者是看了觉得收获不大

- 推荐指数3，推荐。存在一定优点，值得看看

- 推荐指数4，很推荐。知识量较多，结构合理，阅读难度适中

- 推荐指数5，非常推荐。能把人看爽的书
